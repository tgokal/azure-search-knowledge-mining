{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Document Classification Custom Skill\n",
    "\n",
    "This tutorial shows how to deploy a document classification custom skill for Cognitive Search. We will use the document classifier that was created by *01_Train_AML_Model.ipynb*. If you have not already, please run that script.\n",
    "\n",
    "For more information on using custom skills with Cognitive Search, please see this [page](https://docs.microsoft.com/en-us/azure/search/cognitive-search-custom-skill-interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0 Important Variables you need to set for this tutorial\n",
    "\n",
    "Enter your workspace, resource and subscription credentials below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Service Workspace configuration\n",
    "my_workspace_name = 'tg-aml-l400'\n",
    "my_azure_subscription_id = '80a3336a-33ac-4098-a7e7-64eb71d80cee'\n",
    "my_resource_group = 'tg-l400-train'\n",
    "\n",
    "# Azure Kubernetes Service configuration\n",
    "my_aks_location = 'australiaeast'\n",
    "my_aks_compute_target_name = 'aks-comptarget1'\n",
    "my_aks_service_name = 'aks-service1'     \n",
    "my_leaf_domain_label = 'ssl1'   # web service url prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.27.0\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Connect to Workspace\n",
    "Create a workspace object. If you already have a workspace and a config.json file you can use `ws = Workspace.from_config()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tg-aml-l400\taustraliaeast\ttg-l400-train\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.get(name = my_workspace_name, resource_group = my_resource_group, subscription_id = my_azure_subscription_id)\n",
    "print(ws.name, ws.location, ws.resource_group, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Register Model\n",
    "The last step in the training script wrote the file outputs/sklearn_mnist_model.pkl in a directory named outputs.\n",
    "\n",
    "Register the model in the workspace so that you (or other collaborators) can query, examine, and deploy this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model newsgroup_classifier\n",
      "newsgroup_classifier:3\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(model_path=\"outputs/newsgroup_classifier.pkl\",\n",
    "                        model_name=\"newsgroup_classifier\",\n",
    "                        tags={\"data\": \"newsgroup\", \"document\": \"classification\"},\n",
    "                        description=\"document classifier for newsgroup20\",\n",
    "                        workspace=ws)\n",
    "\n",
    "print(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Create Scoring Script\n",
    "Create the scoring script, called score.py, used by the web service call to show how to use the model.\n",
    "\n",
    "You must include two required functions into the scoring script:\n",
    "- The init() function, which typically loads the model into a global object. This function is run only once when the Docker container is started.\n",
    "- The run(input_data) function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported.\n",
    "\n",
    "*The **run function** has been specifically tailored to deploy the model as a custom skill. This means that inputs & outputs are formatted correctly and any errors will be returned in a format usable by Cognitive Search*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # retreive the path to the model file using the model name\n",
    "    model_path = Model.get_model_path(model_name='newsgroup_classifier')\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "def convert_to_df(my_dict):\n",
    "    df = pd.DataFrame(my_dict[\"values\"])\n",
    "    data = df['data'].tolist()\n",
    "    index = df['recordId'].tolist()\n",
    "    return pd.DataFrame(data, index = index)\n",
    "\n",
    "def run(raw_data):\n",
    "    data = json.loads(raw_data)\n",
    "    # Converting the input dictionary to a dataframe\n",
    "    try:\n",
    "        df = convert_to_df(data)\n",
    "    # Returning error message for each item in batch if data not in correct format \n",
    "    except:\n",
    "        df = pd.DataFrame(data)\n",
    "        index = df['recordId'].tolist()\n",
    "        message = \"Request for batch is not in correct format\"\n",
    "        output_list = [{'recordId': i, 'data': {}, \"errors\": [{'message': message}]} for i in index]\n",
    "        return {'values': output_list}\n",
    "    \n",
    "    output_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        output = {'recordId': index, 'data': {}}\n",
    "        try:\n",
    "            output['data']['type'] = str(model.predict([row['content']])[0])\n",
    "        # Returning exception if an error occurs\n",
    "        except Exception as ex:\n",
    "            output['errors'] = [{'message': str(ex)}]\n",
    "        output_list.append(output)\n",
    "\n",
    "    return {'values': output_list}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Create Environment File\n",
    "Next, create an environment file, called myenv.yml, that specifies all of the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. This model needs scikit-learn, pandas, and azureml-sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_conda_package(\"pandas\")\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "- pandas\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"myenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 Create Azure Kubernetes Service Configuration File\n",
    "Estimated time to complete: about 10 minutes\n",
    "\n",
    "Create an Azure Kubernetes Service deployment configuration file. Notice that we enable SSL since Azure Search only allows secure endpoints as custom skills. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine script and environment in an InferenceConfig\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "classifier_inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                              source_directory = 'service_files',\n",
    "                                              entry_script=\"score.py\",\n",
    "                                              conda_file=\"myenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating...................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Define a deployment configuration\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "\n",
    "cluster_name = 'aks-cluster'\n",
    "compute_config = AksCompute.provisioning_configuration(location='australiaeast')\n",
    "production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "production_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target-specific compute specification for deployment\n",
    "\n",
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                              memory_gb = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-05-23 03:06:00+00:00 Creating Container Registry if not exists.\n",
      "2021-05-23 03:06:00+00:00 Registering the environment.\n",
      "2021-05-23 03:06:03+00:00 Building image..\n",
      "2021-05-23 03:13:22+00:00 Creating resources in AKS.\n",
      "2021-05-23 03:13:23+00:00 Submitting deployment to compute.\n",
      "2021-05-23 03:13:23+00:00 Checking the status of deployment classifier-service..\n",
      "2021-05-23 03:15:53+00:00 Checking the status of inference endpoint classifier-service.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Deploy the model\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model = ws.models['newsgroup_classifier']\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name = 'classifier-service',\n",
    "                       models = [model],\n",
    "                       inference_config = classifier_inference_config,\n",
    "                       deployment_config = classifier_deploy_config,\n",
    "                       deployment_target = production_cluster)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Uri: http://20.40.181.245:80/api/v1/service/classifier-service/score\n"
     ]
    }
   ],
   "source": [
    "print('Scoring Uri: ' + service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating............................................................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "ssl1wrpf4w.australiaeast.cloudapp.azure.com Auto\n"
     ]
    }
   ],
   "source": [
    "# # create AKS compute target\n",
    "# from azureml.core.compute import ComputeTarget, AksCompute\n",
    "# config = AksCompute.provisioning_configuration(location= my_aks_location)\n",
    "# config.enable_ssl(leaf_domain_label= my_leaf_domain_label, overwrite_existing_domain=True)\n",
    "\n",
    "# aks = ComputeTarget.create(ws, my_aks_compute_target_name, config)\n",
    "# aks.wait_for_completion(show_output=True)\n",
    "\n",
    "# # if you already created a configuration file, you can just attach: \n",
    "# #config = AksCompute.attach_configuration(resource_group= my_resource_group, cluster_name='enter cluser name here')\n",
    "# #config.enable_ssl(leaf_domain_label= my_leaf_domain_label, overwrite_existing_domain=True)\n",
    "# #aks = ComputeTarget.attach(ws, my_aks_compute_target_name, config)\n",
    "# #aks.wait_for_completion(show_output=True)\n",
    "\n",
    "# print(aks.ssl_configuration.cname, aks.ssl_configuration.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.0 Create Container Image\n",
    "\n",
    "Estimated time to complete: about 7-8 minutes\n",
    "\n",
    "Build an image using:\n",
    "1. The scoring file (score.py)\n",
    "1. The environment file (myenv.yml)\n",
    "1. The model file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: ContainerImage class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n",
      "  import sys\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Image class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running..........................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image sklearn-newsgroup-classifier:4, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# from azureml.core.webservice import  AksWebservice, Webservice\n",
    "# from azureml.core.image import ContainerImage\n",
    "\n",
    "# # build the image\n",
    "# image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "#                                                  runtime = \"python\",\n",
    "#                                                  conda_file = \"myenv.yml\")\n",
    "\n",
    "# image = ContainerImage.create(name = \"sklearn-newsgroup-classifier\",\n",
    "#                               models = [model], \n",
    "#                               image_config = image_config, \n",
    "#                               workspace = ws)\n",
    "\n",
    "# image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.0 Deploy a web service\n",
    "Deploy a web service using the AKS image. Then get the web service HTTPS endpoint and the key to use to call the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from azureml.core.webservice import  AksWebservice, Webservice\n",
    "# from azureml.core.image import ContainerImage\n",
    "\n",
    "# image.update_creation_state()\n",
    "\n",
    "# # deploy an AKS web service using the image (unsure why we have to deploy a new service for the image - perhaps a different way of testing)\n",
    "# aks_config = AksWebservice.deploy_configuration()\n",
    "# service = Webservice.deploy_from_image(workspace = ws,\n",
    "#                                        name = \"aks-image\",\n",
    "#                                        image = image,\n",
    "#                                        deployment_config = aks_config,\n",
    "#                                        deployment_target = aks)\n",
    "\n",
    "\n",
    "# service.wait_for_deployment(show_output = True)\n",
    "primary, secondary = service.get_keys()\n",
    "# print('Scoring Uri: ' + service.scoring_uri)\n",
    "# print('Primary key: ' + primary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.0 Test Deployed Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 Import 20newsgroups Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['comp.graphics', 'sci.space']\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "X_test = newsgroups_test.data\n",
    "y_test = [categories[x] for x in newsgroups_test.target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Format Data in Correct Structure for Cognitive Search\n",
    "For more information on custom skills see this [link](https://docs.microsoft.com/en-us/azure/search/cognitive-search-custom-skill-interface)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'values': [{'recordId': '0', 'data': {'content': 'Subject: PHIGS User Group Conference\\nFrom: hamlin@ug.eds.com (Griff Hamlin)\\nReply-To: hamlin@ug.eds.com (Griff Hamlin)\\nDistribution: world\\nOrganization: EDS Unigraphics, Cypress CA\\nNntp-Posting-Host: 134.244.15.158\\nLines: 173\\n\\n\\n\\n                FIRST ANNUAL PHIGS USER GROUP CONFERENCE\\n\\n          The First Annual PHIGS User Group Conference was held March 21-24\\n          in Orlando, Florida.  The conference was organized by the Rensse-\\n          laer Design Research Center in co-operation with  IEEE  and  SIG-\\n          GRAPH.   Attendees  came  from five countries spanning three con-\\n          tinents.   A  good  cross-section  of  the  PHIGS  community  was\\n          represented  at this conference with participants including PHIGS\\n          users, workstation vendors, third-party PHIGS implementors, stan-\\n          dards  committee  members,  and  researchers  from  industry  and\\n          academia.  The opening speaker, Dr. Richard Puk, challenged PHIGS\\n          users  to  \"take  charge of your PHIGS\" by participating in PHIGS\\n          standardization activities and communicating their needs to PHIGS\\n          implementors.    The   closing  speaker,  Dr.  Andries  Van  Dam,\\n          described his vision of the future of graphics standards  \"beyond\\n          PHIGS\".\\n\\n          Technical paper sessions in the conference covered the  following\\n          topics:  PHIGS  and  X, Application Toolkits, Application Issues,\\n          Texture Mapping, NURBS,  PHIGS  Extensions,  and  Object-Oriented\\n          Libraries and Frameworks.  Panel sessions on PHIGS and PEX, PHIGS\\n          Non-Retained Data, Real-World CAD Applications Using  PHIGS,  and\\n          Portability  Issues generated enthusiastic discussions and formed\\n          a good forum for exchange of ideas, needs, and experiences.   The\\n          conference  also included a day full of tutorials on topics rang-\\n          ing from mathematics for 3D  graphics  to  object-oriented  tools\\n          based on PHIGS.\\n\\n          Next year\\'s conference is planned for March, 1994.\\n\\n          PHIGS EVERYWHERE\\n\\n          At the conference, PHIGS  vendors   described   and  demonstrated\\n          PHIGS  products  that  run on all types of computers, from PCs to\\n          mainframes.\\n\\n          Megatek Corporation demonstrated their PHIGS extensions including\\n          conditional traversal, composite logical input devices, texturing\\n          and translucency.\\n\\n          Template Graphics  Software  launched  FIGARO+  PRO,  the  Photo-\\n          Realistic  Option  for  PHIGS+.  FIGARO+  PRO  is designed to add\\n          advanced rendering to the existing PHIGS+ API, with features like\\n          ray   tracing,  materials,  anti-aliasing  and  texture  mapping.\\n          Radiosity support is also planned.\\n\\n          FIGARO+ is an example of how TGS continues to add newly  emerging\\n          graphics  features to their products.  FIGARO+ supports immediate\\n          mode extensions to PHIGS and also supports SUN XGL,  HP  Starbase\\n          and SGI GL/OpenGL. FIGARO+ for NT will be released this summer.\\n\\n          TGS also demonstrated the latest versions of FIGraph, a  powerful\\n          \"2-call\"  charting  system  based on PHIGS+, and FIGt, an object-\\n          oriented utility library for PHIGS/PEX developers.\\n\\n          G5G and Gallium Software demonstrated a new version of GPHIGS  on\\n          Silicon  Graphics  workstations. Scheduled for summer, 1993, Ver-\\n          sion 3.0 of GPHIGS, the company\\'s  PHIGS+  library  for  worksta-\\n          tions,  will include an advanced PHIGS debugger that allows PHIGS\\n          developers to display and browse PHIGS structures and other PHIGS\\n          internal  state.  G5G  also  described  their Non-Duplicated Data\\n          Store that stores pointers to application data in the GPHIGS  CSS\\n          for  more  efficient  use  of  memory. In addition, G5G described\\n          their application GSE that allows application callback  functions\\n          during  GPHIGS traversal.  GPHIGS and PHIGURE, G5G\\'s data visual-\\n          izer and application development toolkit, are currently available\\n          on  all  major  workstations  that support GL, X Windows, PEX, or\\n          Starbase.\\n\\n          Wise Software presented a slide show of  Z-PHIGS  for  MS-Windows\\n          and ARENA, a PHIGS based modeller/render. Z-PHIGS implements most\\n          of the PHIGS+ primitives.  In addition Z-PHIGS has built in  many\\n          advanced  rendering features like texture mapping, shadow genera-\\n          tion, area quick updates and ray tracing. A demo disk of  Z-PHIGS\\n          or ARENA is available on request.\\n\\n          ATC exhibited GRAFPAK-PHIGS, their full-featured PHIGS  implemen-\\n          tation  based  on  DEC  PHIGS. GRAFPAK-PHIGS is available on most\\n          workstation platforms with C, FORTRAN and Ada bindings and incor-\\n          porates PEX support.\\n\\n          Within the booth sponsored by Advanced Technology Center, Digital\\n          Equipment  Corporation demonstrated DEC PHIGS V2.4 running on the\\n          DEC 3000/400 AXP PXG. ATCs\\' GRAFPAK-PHIGS is a port of DEC PHIGS.\\n          DEC  PHIGS  V2.4 contains most PHIGS and PHIGS PLUS features with\\n          support for PEX V5.1  protocol.  DEC  PHIGS  also  contains  most\\n          GM/EDS   PHIGS  extensions  including  post-to-view  as  well  as\\n          proprietary extensions to support immediate  mode  rendering  and\\n          the use of PHIGS in an X11 environment.\\n\\n          AXP, DEC, and DEC PHIGS are trademarks of Digital Equipment  Cor-\\n          poration.  GRAFPAK-PHIGS and ATC are trademarks of Advanced Tech-\\n          nology Center. PEX and X11 are trademarks of Massachusetts Insti-\\n          tute of Technology.\\n\\n          The IBM exhibit featured a GTO accelerator attached to an IBM 340\\n          workstation running graPHIGS and PEX.\\n\\n          Hewlett Packard and SHOgraphics demonstrated at the conference. A\\n          Hewlett  Packard  machine was coupled to display on a SHOgraphics\\n          PEX terminal. HP showcased their latest  PHIGS  product  enhance-\\n          ments.\\n\\n\\n          PHIGS USER GROUP\\n\\n          The PHIGS Users Group was formed to aid the development of  PHIGS\\n          applications  and provide user feedback to PHIGS implementors and\\n          PHIGS standards bodies.  For more  information  about  the  PHIGS\\n          Users Group, send e-mail to:\\n\\n                    phigsug@cadrt10.me.vt.edu\\n\\n          or write to:\\n\\n                    Sankar Jayaram\\n                    Virginia Polytechnic Institute\\n                    114 Randolph Hall\\n                    Blacksburg, Va. 24061-0238\\n                    FAX: 703-231-9100\\n\\n\\n          VENDOR CONTACTS\\n\\n          Megatek Corporation\\n          TEL (619) 455-5590\\n          FAX (619) 453-7603\\n\\n          Template Graphics Software\\n          TEL (800) 544-4847\\n          FAX (619) 452-2547\\n\\n          WISE software GmbH\\n          TEL +49-451-3909-413\\n          FAX +49-451-3909-499\\n\\n          G5G - North American Sales\\n          TEL (800) 267-2626\\n          FAX (613) 592-1278\\n\\n          Advanced Technology Center\\n          TEL (800) 999-5711\\n          FAX (714) 583-9213\\n\\n          Digital Equipment Corporation\\n          TEL (603) 884-5111\\n\\n          International Business Machines Corporation\\n          TEL (800) 426-3333\\n\\n          Hewlett Packard Company\\n          TEL (303) 229-3800\\n\\n          COPIES OF THE CONFERENCE PROCEEDINGS\\n\\n          Copies of the conference proceedings may be obtained by  contact-\\n          ing Mary Johnson at:\\n\\n                    Johnson, Mary\\n                    Design and Manufacturing Institute\\n                    Rensselaer Polytechnic Institute\\n                    110 Eighth Street\\n                    Building CII, Room 7015\\n                    Troy, NY  12180-3590\\n                    Tel:  (518)276-6754\\n                    Fax:  (518)276-2702\\n                    Email:  mjohnson@rdrc.rpi.edu\\n\\n\\n          The cost is $75.00 per binder.\\n\\n'}}]}\n"
     ]
    }
   ],
   "source": [
    "# send a random row from the test set to score\n",
    "random_index = np.random.randint(0, len(X_test)-1)\n",
    "\n",
    "input_data = {\"values\":[{\"recordId\": \"0\", \"data\": {\"content\": newsgroups_test.data[random_index]}}]}\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3 Send HTTP Request and View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url http://20.40.181.245:80/api/v1/service/classifier-service/score\n",
      "label: comp.graphics\n",
      "prediction: {\"values\": [{\"recordId\": \"0\", \"data\": {\"type\": \"comp.graphics\"}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "input_json = json.dumps(input_data)\n",
    "\n",
    "headers = { 'Content-Type':'application/json'}\n",
    "headers['Authorization']= f'Bearer {primary}'\n",
    "\n",
    "# for AKS deployment you'd need the service key in the header as well\n",
    "# api_key = service.get_key()\n",
    "# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_json, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"label:\", y_test[random_index])\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
