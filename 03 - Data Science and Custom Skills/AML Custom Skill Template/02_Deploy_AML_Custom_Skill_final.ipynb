{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Document Classification Custom Skill\n",
    "\n",
    "This tutorial shows how to deploy a document classification custom skill for Cognitive Search. We will use the document classifier that was created by *01_Train_AML_Model.ipynb*. If you have not already, please run that script.\n",
    "\n",
    "For more information on using custom skills with Cognitive Search, please see this [page](https://docs.microsoft.com/en-us/azure/search/cognitive-search-custom-skill-interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0 Important Variables you need to set for this tutorial\n",
    "\n",
    "Enter your workspace, resource and subscription credentials below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Service Workspace configuration\n",
    "my_workspace_name = 'tg-aml-l400'\n",
    "my_azure_subscription_id = '80a3336a-33ac-4098-a7e7-64eb71d80cee'\n",
    "my_resource_group = 'tg-l400-train'\n",
    "\n",
    "# Azure Kubernetes Service configuration\n",
    "my_aks_location = 'australiaeast'\n",
    "my_aks_compute_target_name = 'aks-comptarget1'\n",
    "my_aks_service_name = 'aks-service1'     \n",
    "my_leaf_domain_label = 'ssl1'   # web service url prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.27.0\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Connect to Workspace\n",
    "Create a workspace object. If you already have a workspace and a config.json file you can use `ws = Workspace.from_config()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tg-aml-l400\taustraliaeast\ttg-l400-train\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.get(name = my_workspace_name, resource_group = my_resource_group, subscription_id = my_azure_subscription_id)\n",
    "print(ws.name, ws.location, ws.resource_group, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Register Model\n",
    "The last step in the training script wrote the file outputs/sklearn_mnist_model.pkl in a directory named outputs.\n",
    "\n",
    "Register the model in the workspace so that you (or other collaborators) can query, examine, and deploy this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model newsgroup_classifier\n",
      "newsgroup_classifier:3\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(model_path=\"outputs/newsgroup_classifier.pkl\",\n",
    "                        model_name=\"newsgroup_classifier\",\n",
    "                        tags={\"data\": \"newsgroup\", \"document\": \"classification\"},\n",
    "                        description=\"document classifier for newsgroup20\",\n",
    "                        workspace=ws)\n",
    "\n",
    "print(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Create Scoring Script\n",
    "Create the scoring script, called score.py, used by the web service call to show how to use the model.\n",
    "\n",
    "You must include two required functions into the scoring script:\n",
    "- The init() function, which typically loads the model into a global object. This function is run only once when the Docker container is started.\n",
    "- The run(input_data) function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported.\n",
    "\n",
    "*The **run function** has been specifically tailored to deploy the model as a custom skill. This means that inputs & outputs are formatted correctly and any errors will be returned in a format usable by Cognitive Search*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # retreive the path to the model file using the model name\n",
    "    model_path = Model.get_model_path(model_name='newsgroup_classifier')\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "def convert_to_df(my_dict):\n",
    "    df = pd.DataFrame(my_dict[\"values\"])\n",
    "    data = df['data'].tolist()\n",
    "    index = df['recordId'].tolist()\n",
    "    return pd.DataFrame(data, index = index)\n",
    "\n",
    "def run(raw_data):\n",
    "    data = json.loads(raw_data)\n",
    "    # Converting the input dictionary to a dataframe\n",
    "    try:\n",
    "        df = convert_to_df(data)\n",
    "    # Returning error message for each item in batch if data not in correct format \n",
    "    except:\n",
    "        df = pd.DataFrame(data)\n",
    "        index = df['recordId'].tolist()\n",
    "        message = \"Request for batch is not in correct format\"\n",
    "        output_list = [{'recordId': i, 'data': {}, \"errors\": [{'message': message}]} for i in index]\n",
    "        return {'values': output_list}\n",
    "    \n",
    "    output_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        output = {'recordId': index, 'data': {}}\n",
    "        try:\n",
    "            output['data']['type'] = str(model.predict([row['content']])[0])\n",
    "        # Returning exception if an error occurs\n",
    "        except Exception as ex:\n",
    "            output['errors'] = [{'message': str(ex)}]\n",
    "        output_list.append(output)\n",
    "\n",
    "    return {'values': output_list}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Create Environment File\n",
    "Next, create an environment file, called myenv.yml, that specifies all of the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. This model needs scikit-learn, pandas, and azureml-sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_conda_package(\"pandas\")\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "- pandas\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"myenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 Create Azure Kubernetes Service Configuration File\n",
    "Estimated time to complete: about 10 minutes\n",
    "\n",
    "Create an Azure Kubernetes Service deployment configuration file. Notice that we enable SSL since Azure Search only allows secure endpoints as custom skills. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine script and environment in an InferenceConfig\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "classifier_inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                              source_directory = 'service_files',\n",
    "                                              entry_script=\"score.py\",\n",
    "                                              conda_file=\"myenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a deployment configuration\n",
    "# from azureml.core.compute import ComputeTarget, AksCompute\n",
    "\n",
    "# cluster_name = 'aks-cluster'\n",
    "# compute_config = AksCompute.provisioning_configuration(location='australiaeast')\n",
    "# production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "# production_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating.................................................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "ssl1xxkjd7.australiaeast.cloudapp.azure.com Auto\n"
     ]
    }
   ],
   "source": [
    "# # Create AKS compute target and define a deployment configuration\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "\n",
    "config = AksCompute.provisioning_configuration(location= my_aks_location)\n",
    "config.enable_ssl(leaf_domain_label= my_leaf_domain_label, overwrite_existing_domain=True)\n",
    "aks = ComputeTarget.create(ws, my_aks_compute_target_name, config)\n",
    "aks.wait_for_completion(show_output=True)\n",
    "print(aks.ssl_configuration.cname, aks.ssl_configuration.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target-specific compute specification for deployment\n",
    "\n",
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                              memory_gb = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-05-23 07:43:27+00:00 Creating Container Registry if not exists.\n",
      "2021-05-23 07:43:27+00:00 Registering the environment.\n",
      "2021-05-23 07:43:29+00:00 Use the existing image..\n",
      "2021-05-23 07:43:31+00:00 Creating resources in AKS.\n",
      "2021-05-23 07:43:33+00:00 Submitting deployment to compute.\n",
      "2021-05-23 07:43:33+00:00 Checking the status of deployment classifier-service..\n",
      "2021-05-23 07:46:32+00:00 Checking the status of inference endpoint classifier-service.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Deploy the model\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model = ws.models['newsgroup_classifier']\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name = 'classifier-service',\n",
    "                       models = [model],\n",
    "                       inference_config = classifier_inference_config,\n",
    "                       deployment_config = classifier_deploy_config,\n",
    "                       deployment_target = aks)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Uri: https://ssl1xxkjd7.australiaeast.cloudapp.azure.com:443/api/v1/service/classifier-service/score\n"
     ]
    }
   ],
   "source": [
    "print('Scoring Uri: ' + service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.0 Create Container Image\n",
    "\n",
    "Estimated time to complete: about 7-8 minutes\n",
    "\n",
    "Build an image using:\n",
    "1. The scoring file (score.py)\n",
    "1. The environment file (myenv.yml)\n",
    "1. The model file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: ContainerImage class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n",
      "  import sys\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Image class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running..........................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image sklearn-newsgroup-classifier:4, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# from azureml.core.webservice import  AksWebservice, Webservice\n",
    "# from azureml.core.image import ContainerImage\n",
    "\n",
    "# # build the image\n",
    "# image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "#                                                  runtime = \"python\",\n",
    "#                                                  conda_file = \"myenv.yml\")\n",
    "\n",
    "# image = ContainerImage.create(name = \"sklearn-newsgroup-classifier\",\n",
    "#                               models = [model], \n",
    "#                               image_config = image_config, \n",
    "#                               workspace = ws)\n",
    "\n",
    "# image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.0 Deploy a web service\n",
    "Deploy a web service using the AKS image. Then get the web service HTTPS endpoint and the key to use to call the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary key is:  nLhUE4vtbbJ3NjpFChm8CH6AZvGdLrqc\n"
     ]
    }
   ],
   "source": [
    "# from azureml.core.webservice import  AksWebservice, Webservice\n",
    "# from azureml.core.image import ContainerImage\n",
    "\n",
    "# image.update_creation_state()\n",
    "\n",
    "# # deploy an AKS web service using the image (unsure why we have to deploy a new service for the image - perhaps a different way of testing)\n",
    "# aks_config = AksWebservice.deploy_configuration()\n",
    "# service = Webservice.deploy_from_image(workspace = ws,\n",
    "#                                        name = \"aks-image\",\n",
    "#                                        image = image,\n",
    "#                                        deployment_config = aks_config,\n",
    "#                                        deployment_target = aks)\n",
    "\n",
    "\n",
    "# service.wait_for_deployment(show_output = True)\n",
    "primary, secondary = service.get_keys()\n",
    "print('Primary key is: ', primary)\n",
    "# print('Scoring Uri: ' + service.scoring_uri)\n",
    "# print('Primary key: ' + primary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.0 Test Deployed Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 Import 20newsgroups Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['comp.graphics', 'sci.space']\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "X_test = newsgroups_test.data\n",
    "y_test = [categories[x] for x in newsgroups_test.target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Format Data in Correct Structure for Cognitive Search\n",
    "For more information on custom skills see this [link](https://docs.microsoft.com/en-us/azure/search/cognitive-search-custom-skill-interface)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'values': [{'recordId': '0', 'data': {'content': 'From: jbh55289@uxa.cso.uiuc.edu (Josh Hopkins)\\nSubject: Re: Vandalizing the sky.\\nOrganization: University of Illinois at Urbana\\nLines: 40\\n\\nrbunge@access.digex.net (Robert Bunge) writes:\\n\\n>In article <C69AGI.MJu@news.cso.uiuc.edu> jbh55289@uxa.cso.uiuc.edu (Josh Hopkins) writes:\\n>>I\\'m wondering if \"vandalize\" is the proper word to use in this situation.  My\\n>>dictionary defines \"vandalism\" as \"the willful or malicious destructuion of \\n>>public or private property, especially of anything beautiful or artisitc.\" I\\n>>would agree the sky is beautiful, but not that it is public or private property.\\n\\n>It\\'s public because it belongs to everybody. \\n\\nNo, the sky does not, at this time, belong to anyone.  Ownership is necessary\\nto the definition because someone has to have the authority to decide if the\\naction was good or bad.  If neither you or I own a brick wall, then I can\\'t\\nunilaterally declare that spraypainting my name on it is right, and you don\\'t\\nhave the authority to declare that it is wrong.  The owner may find it artistic\\nor she may be call the police.\\n\\n(this applies to the argument on bright satellites more than street lights)\\n\\nIt\\'s vandalism because many people -- power companies -- do maliciously waste light. \\n\\n\"maliciously\" implies evil intent.  The lighting companies aren\\'t going out\\nof their way to spoil the sky.  They just don\\'t care.\\n\\n>If they can sell you\\n>or your city or your state an unshielded light that wastes 30 to 50 percent\\n>of its light, they make more _money_.  Never mind that your money is wasted.\\n\\nIt is the responsibility of the customer to choose the most efficient hardware.\\nIf that\\'s what your city will buy, that\\'s what the lighting company will sell.\\nWrite a letter to city hall.\\n\\nPlease note that I\\'m not defending light pollution.  The orignial focus of \\nthis thread was space based light sources.\\n\\n\\n-- \\nJosh Hopkins                                          jbh55289@uxa.cso.uiuc.edu\\n\\t\\t    \"Find a way or make one.\"\\n\\t             -attributed to Hannibal\\n'}}]}\n"
     ]
    }
   ],
   "source": [
    "# send a random row from the test set to score\n",
    "random_index = np.random.randint(0, len(X_test)-1)\n",
    "\n",
    "input_data = {\"values\":[{\"recordId\": \"0\", \"data\": {\"content\": newsgroups_test.data[random_index]}}]}\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3 Send HTTP Request and View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url https://ssl1xxkjd7.australiaeast.cloudapp.azure.com:443/api/v1/service/classifier-service/score\n",
      "label: sci.space\n",
      "prediction: {\"values\": [{\"recordId\": \"0\", \"data\": {\"type\": \"sci.space\"}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "input_json = json.dumps(input_data)\n",
    "\n",
    "headers = { 'Content-Type':'application/json'}\n",
    "headers['Authorization']= f'Bearer {primary}'\n",
    "\n",
    "# for AKS deployment you'd need the service key in the header as well\n",
    "# api_key = service.get_key()\n",
    "# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_json, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"label:\", y_test[random_index])\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
